\chapter{Conclusões e Trabalho Futuro} \label{chap:concl}

Neste capítulo é apresentado um resumo de todo o trabalho realizado, são discutidas algumas conclusões retiradas do desenvolvimento desta dissertação e são apresentadas sugestões para trabalho futuro.

\section{Resumo}

Durante o período dedicado à realização do projeto de dissertação, foi seguida uma sequência de etapas que culminou num sistema capaz de identificar e visualizar \textit{clusters} no espaço, no tempo e através do conteúdo, em particular, das imagens. Este também permitiu visualizar e navegar por fotografias partilhadas no serviço de \textit{microblogging} Twitter contidas num determinado \textit{cluster}.

Inicialmente foi feita uma recolha dos dados necessários para o desenvolvimento deste projeto de dissertação. Este dados foram recolhidos através de base de dados MongoDB e possuíam a informação relativa a tweets partilhados na rede social Twitter. Este tweets eram uma amostra com a duração de três dias que continham, na sua maioria, conteúdo relativo às manifestações que ocorreram em Junho de 2013 no Brasil. Como o objetivo era a descoberta de padrões através de fotografias, foi necessário armazenar localmente todas as imagens partilhadas no Twitter. Devido ao número muito pequeno de imagens partilhadas diretamente pelo Twitter, foi necessário optar por imagens com origem no serviço de partilha de imagens Instagram, por este permitir o acesso a um número bem superior de imagens. Os dados desses tweets também foram armazenados no formato JSON.

O passo seguinte passou pelo desenvolvimento de um módulo responsável pela extração e processamento de informação visual para descrever as imagens. Para isto foi criado um vocabulário visual de tamanho fixo utilizando o descritor local SIFT. Este módulo foi também responsável pelo armazenamento da informação visual numa base de dados local. O desenvolvimento deste módulo permitiu uma representação das imagens de uma forma mais eficiente e compacta, e tornou possível a comparação entre imagens para a criação de uma matriz de distâncias para ser utilizada na tarefa de \textit{clustering} do processo de \textit{Data Mining}. Para o cálculo das distâncias entre as imagens, isto é, a distância entre os vetores descritores das imagens, foi utilizada a função de distância Euclidiana.

Prosseguiu-se com a produção das matrizes de distância entre tweets, utilizando as funções de distância de intervalo de tempo e Haversine, respetivamente para a dimensão temporal e espacial. Posteriormente foi realizada a normalização das matrizes através da função mínimo-máximo. Com as matrizes criadas e normalizadas foi possível realizar várias combinações entre as três diferentes dimensões atribuindo pesos diferentes a cada. Com esta integração concluída, estavam reunidas as condições para utilizar esta informação no processo de \textit{Data Mining} desenvolvido no Tweeprofiles para a obtenção dos \textit{clusters} com o algoritmo DBSCAN.

Foi desenvolvida a aplicação web em Python, recorrendo a microframework Flask, para visualização dos resultados através do conteúdo dos tweets e das diferentes dimensões já referidas. Uma mapa e um gráfico temporal foram implementados utilizando diferentes bibliotecas Javascript. Também utilizando a linguagem Javascript foi desenvolvido um \textit{widget} que permite navegação pelo conteúdo visual e pela informação dos tweets respetivos, incluindo a possibilidade de acesso ao tweet original. Foram ainda adicionados controlos para a seleção do peso atribuído a cada dimensão e seleção de três diferentes intervalos de tempo.

Após a finalização deste projeto de dissertação foi feita uma análise a todo o processo realizado, tendo sido concluído que os objetivos principais propostos foram atingidos. Apesar disso, alguns objetivos mais ambiciosos não foram atingidos devido a um conjuntos diversificado de fatores. Na próxima secção são discutidos algumas decisões tomadas e sugeridas alternativas possíveis a considerar de forma a que possam ser atingidos objetivos mais ambiciosos e dar continuidade a este projeto num trabalho futuro.

\section{Discusão e trabalho futuro}

Nesta secção serão discutidas algumas decisões tomadas e apresentadas sugestões para trabalho futuro.

\begin{description}
\item [Base de dados:] 
A base de dados utilizada apresentava um conjunto de dados muito especifico como já foi referido anteriormente. A escolha deste conjunto teve como principal objetivo tentar encontrar padrões num evento, como foi o caso das manifestações no Brasil. Para além disto, este evento garantiu-nos um acesso a um número significativo de fotografias. No entanto seria interessante analisar os resultados utilizando uma base de dados mais diversificada. Isto é, base de dados com tweets relativos a eventos mais específicos e outras com dados mais genéricos. %  e com um maior número de tweets para garantir o aquisição de mais imagens contidas tweets com georeferenciação.

\item [Módulo informação visual:]
Apesar de não ter sido realizado um estudo empírico sobre o desempenho das várias alternativas de representação da informação visual descritas na Secção~\ref{sec:represent}, o método escolhido, SIFT, obteve resultados que levaram consequentemente a resultados finais que, por inspeção visual, parecem frequentemente adequados. No entanto, é importante referir que no trabalho futuro pode fazer sentido realizar uma análise mais aprofundada.

Já na criação do vocabulário visual, apenas foram utilizadas cerca de 8\% do total de imagens armazenas devido a limitações de memória computacional. Assim no trabalho futuro, deverá ser tido em conta a utilização de um número maior de imagens para garantir um vocabulário mais robusto.

%O funcionamento global deste módulo apresentou um bom desempenho, pois tal como esperado, a escolha do descritor SIFT para a criação do vocabulário visual revelou ter sido uma escolha acertada. Este é utilizado em diferentes situações, tais como, reconhecimento de objetos ou pesquisa de imagens semelhantes, apresentado sempre bons resultados. Para a criação deste vocabulário visual apenas foram utilizadas cerca de 8\% do total de imagens armazenas devido a limitações de memória computacional. Assim num trabalho futuro, a utilização de um número maior de imagens para garantir um vocabulário mais rigoroso deverá ser tida em conta. 

Outro aspeto a ser considerado seria, a conjugação do descritor de cor com o vocabulário visual para descrever as imagens. Isto possibilitaria uma melhor descrição das imagens e permitiria distinguir mais eficazmente cenários onde a cor é um fator distintivo, como por exemplo, fotografias de praias, alimentos ou mesmo locais com vegetação, como jardins ou parques naturais onde predomina a cor verde. Esta opção poderia ser disponibilizada ao utilizador, decidindo este se pretende utilizá-la ou não. Esta deve ser optativa pois foi verificado que quando se procura casos de conjuntos de imagens onde o conteúdo é por exemplo textos ou desenhos, a utilização da descritor de cor seria irrelevante podendo-se considerar, neste caso, a inclusão de ruído nos dados.

\item [Matrizes de distância:]
No caso da matriz relativa ao conteúdo visual, a função de distância Euclidiana foi utilizada para a comparação entre os histogramas com a descrição do vocabulário visual de cada imagem garante um cálculo rápido e eficiente, mas a utilização de uma função mais especifica para cálculo de distância entre histogramas, deverá ser considerada no trabalho futuro.

Para a combinação das matrizes foram utilizados passos de 33.33\% pois este permitiu a existência de uma combinação com pesos iguais para as diferentes dimensões. A utilização de passos mais pequenos foi considerada, mas esta iria fazer crescer muito o número de combinações possíveis. %No entanto não sabemos se a utilização de passos deste grau tem impacto na perda de informação interessante na criação dos \textit{clusters}.

Para a normalização das matrizes foi utilizada a função de normalização mínimo-máximo para poder utilizar o algoritmo de \textit{clustering} com parâmetros baseados em percentagens. A utilização da normalização \textit{z-score} através da média e desvio padrão é uma alternativa que altera a distribuição de densidade de forma a aproximá-la da distribuição normal, apresentando valores em torno de zero, incluindo valores negativos. O problema é que uma matriz de distância não pode ter valores negativos. Assim a primeira opção tornou-se a mais viável, para uma primeira abordagem, principalmente tendo em conta que este não era o objetivo principal do projeto.

É de salientar ainda que a distância social não foi incluída por ter sido um dos aspetos menos desenvolvidos no TweeProfiles e por isso não foi tratado neste projeto.

\item [Processo de Data Mining:]
Visto que o objetivo principal desta dissertação não passava por melhorar o processo de análise de dados desenvolvido no projeto TweeProfiles, mas sim estendê-lo para incorporar imagens na dimensão de conteúdo, optou-se por seguir o modelo desenvolvido no TweeProfiles. Assim o algoritmo DBSCAN foi o aplicado neste processo, em que o parâmetro do raio deste algoritmo foi de 10\%, o mesmo utilizado no TweeProfiles. Apesar de após a normalização as matrizes das diferentes dimensões apresentarem a mesma escala, a forma da distribuição das distâncias difere de dimensão para dimensão. Assim o valor do raio definido tem uma influência diferente em cada dimensão. No entanto, não temos conhecimento do impacto desta decisão nos resultados. Assim, seria importante um estudo mais aprofundado do impacto deste parâmetro em cada uma das dimensões e adaptá-lo de forma a que este seja tenha um comportamento similar em todas as dimensões. Aliás, esta questão insere-se num contexto mais geral de avaliação dos resultados do \textit{clustering} no âmbito do projeto TweeProfiles e suas extensões. Até agora, esta questão teve sempre pouca prioridade. No entanto, à medida que a ferramenta se consolida, torna-se cada vez mais importante fazer um estudo empírico da qualidade dos \textit{clusterings}, tanto em termos de medidas estatísticas como em termos de aplicações do conhecimento produzido.

É também importante referir que em paralelo ao desenvolvimento deste projeto de dissertação foi também desenvolvido a segunda versão do TweeProfiles por João Pereira do Mestrado Integrado em Engenharia Informática e Computação da Faculdade de Engenharia da Universidade do Porto. Esta nova versão tem o objetivo de descobrir padrões em tempo real, utilizando \textit{stream} de dados. Isto torna ferramenta mais adaptada à realidade das redes sociais como o Twitter, em que os dados nos chegam a todo o instante. Assim, como trabalho futuro, um dos objetivos principais poderá passar pela implementação da mesma metodologia no Olhó-passarinho. 

\item [Visualização:]
O TweeProfiles foi desenvolvido utilizado a linguagem R em todo processo de recolha, tratamento e processamento dos dados e a sua aplicação web baseou-se na tecnologia Java. Visto que no caso do Olhó-passarinho foi necessário utilizar algoritmos de visão por computador, a linguagem Python foi a escolhida por permitir utilizar bibliotecas para este fim, e ao mesmo tempo adicionar bibliotecas para aceder à base de dados MongoDB, manipular os dados e ter também acesso a bibliotecas para utilização da linguagem R. Assim optou-se por também no desenvolvimento da aplicação web para a visualização dos resultados desenvolver uma nova ferramenta utilizando a linguagem Python. Para isso foi utilizado a \textit{microframework} Flask que assenta nesta tecnologia e permite a simulação de um servidor em Python. Já no caso dos \textit{widgets} para visualização foi seguido um padrão semelhante ao TweeProfiles, onde também foi adicionado um mapa e gráfico para respetivamente representar a distribuição espacial e temporal dos \textit{clusters}. 

No caso da secção para visualização do conteúdo visual, optou-se por uma matriz de imagens, visto esta ser uma das formas mais utilizadas em redes sociais para a visualização de conjuntos de imagens e permitir uma fácil comparação e navegação por entre as mesma. 
Uma das possibilidades num trabalho futuro seria a sintetização de uma imagem capaz de representar um \textit{cluster} de forma eficaz. No caso da visualização de uma imagem especifica também seria interessante a visualização das N imagens mais próximas, onde N seria um número pré-definido.

\end{description}

Em suma, 
